"""
NVDA Vision - è§†è§‰è¯†åˆ«æµ‹è¯•è„šæœ¬

åœ¨OpenSandboxä¸­æµ‹è¯•è§†è§‰æ¨¡åž‹çš„è¯†åˆ«èƒ½åŠ›ã€‚
"""

from opensandbox import Sandbox
from datetime import timedelta
import asyncio
import sys
from pathlib import Path
from typing import List, Dict
import json


class VisionTestRunner:
    """è§†è§‰è¯†åˆ«æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(
        self,
        image: str = "nvda-vision:latest",
        timeout_minutes: int = 15,
        verbose: bool = True
    ):
        self.image = image
        self.timeout = timedelta(minutes=timeout_minutes)
        self.verbose = verbose
        self.sandbox = None

    async def setup_sandbox(self):
        """åˆ›å»ºæ²™ç®±"""
        if self.verbose:
            print(f"ðŸš€ åˆ›å»ºæ²™ç®±: {self.image}")

        self.sandbox = await Sandbox.create(
            self.image,
            timeout=self.timeout,
            env={
                "PYTHON_VERSION": "3.11",
                "NVDA_LOG_LEVEL": "DEBUG",
                "CACHE_ENABLED": "false"  # ç¦ç”¨ç¼“å­˜ä»¥æµ‹è¯•å®žé™…æŽ¨ç†
            }
        )

        if self.verbose:
            print("âœ… æ²™ç®±åˆ›å»ºæˆåŠŸ\n")

    async def upload_test_images(self, image_paths: List[str]):
        """ä¸Šä¼ æµ‹è¯•å›¾ç‰‡åˆ°æ²™ç®±"""
        if self.verbose:
            print(f"ðŸ“¤ ä¸Šä¼  {len(image_paths)} å¼ æµ‹è¯•å›¾ç‰‡...")

        for img_path in image_paths:
            local_path = Path(img_path)
            if not local_path.exists():
                print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                continue

            with open(local_path, "rb") as f:
                content = f.read()
                remote_path = f"/app/tests/fixtures/screenshots/{local_path.name}"

                await self.sandbox.files.write_files([{
                    "path": remote_path,
                    "content": content
                }])

                if self.verbose:
                    print(f"  âœ… {local_path.name}")

        if self.verbose:
            print()

    async def test_model_inference(
        self,
        model_name: str,
        test_image: str
    ) -> Dict:
        """
        æµ‹è¯•ç‰¹å®šæ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›

        Args:
            model_name: æ¨¡åž‹åç§° (UI-TARS, MiniCPM-V, Doubao)
            test_image: æµ‹è¯•å›¾ç‰‡è·¯å¾„ï¼ˆæ²™ç®±å†…è·¯å¾„ï¼‰

        Returns:
            æµ‹è¯•ç»“æžœå­—å…¸
        """
        if self.verbose:
            print(f"ðŸ” æµ‹è¯•æ¨¡åž‹: {model_name}")
            print(f"   å›¾ç‰‡: {test_image}")

        # Pythonæµ‹è¯•è„šæœ¬
        test_script = f'''
import asyncio
import json
import time
from src.vision_engine import VisionEngine
from src.config import ConfigManager

async def test_model():
    config = ConfigManager()
    engine = VisionEngine(config)

    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()

    try:
        # æ‰§è¡Œè¯†åˆ«
        result = await engine.recognize(
            "{test_image}",
            preferred_model="{model_name}"
        )

        # è®¡ç®—è€—æ—¶
        inference_time = time.time() - start_time

        # è¾“å‡ºç»“æžœJSON
        output = {{
            "success": True,
            "model": "{model_name}",
            "inference_time": inference_time,
            "elements_count": len(result.elements),
            "average_confidence": result.average_confidence,
            "elements": [
                {{
                    "type": elem.type,
                    "text": elem.text,
                    "confidence": elem.confidence,
                    "bbox": elem.bbox
                }}
                for elem in result.elements[:10]  # å‰10ä¸ªå…ƒç´ 
            ]
        }}

        print(json.dumps(output, ensure_ascii=False, indent=2))

    except Exception as e:
        output = {{
            "success": False,
            "model": "{model_name}",
            "error": str(e)
        }}
        print(json.dumps(output, ensure_ascii=False, indent=2))

asyncio.run(test_model())
'''

        # åœ¨æ²™ç®±ä¸­è¿è¡Œ
        result = await self.sandbox.commands.run(
            f"cd /app && python -c '{test_script}'"
        )

        if result.exit_code != 0:
            if self.verbose:
                print(f"âŒ æµ‹è¯•å¤±è´¥:")
                print(result.stderr)
            return {"success": False, "error": result.stderr}

        # è§£æžJSONè¾“å‡º
        try:
            output = json.loads(result.stdout)

            if self.verbose and output.get("success"):
                print(f"âœ… è¯†åˆ«æˆåŠŸ!")
                print(f"   æŽ¨ç†æ—¶é—´: {output['inference_time']:.2f}ç§’")
                print(f"   è¯†åˆ«å…ƒç´ : {output['elements_count']}ä¸ª")
                print(f"   å¹³å‡ç½®ä¿¡åº¦: {output['average_confidence']:.2%}\n")

                # æ˜¾ç¤ºå‰5ä¸ªå…ƒç´ 
                if output.get("elements"):
                    print("   å‰5ä¸ªå…ƒç´ :")
                    for i, elem in enumerate(output["elements"][:5], 1):
                        print(f"     {i}. {elem['type']}: {elem['text'][:30]} "
                              f"(ç½®ä¿¡åº¦: {elem['confidence']:.2%})")
                    print()

            return output

        except json.JSONDecodeError:
            if self.verbose:
                print(f"âš ï¸ æ— æ³•è§£æžè¾“å‡º:")
                print(result.stdout)
            return {"success": False, "error": "Invalid JSON output"}

    async def test_all_models(self, test_image: str) -> Dict[str, Dict]:
        """æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡åž‹"""
        models = ["UI-TARS", "MiniCPM-V", "Doubao"]
        results = {}

        if self.verbose:
            print("=" * 70)
            print("ðŸ§ª æµ‹è¯•æ‰€æœ‰è§†è§‰æ¨¡åž‹")
            print("=" * 70)
            print()

        for model in models:
            try:
                result = await self.test_model_inference(model, test_image)
                results[model] = result
            except Exception as e:
                if self.verbose:
                    print(f"âŒ {model} æµ‹è¯•å¤±è´¥: {e}\n")
                results[model] = {"success": False, "error": str(e)}

        return results

    async def test_cache_performance(self, test_image: str):
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        if self.verbose:
            print("=" * 70)
            print("âš¡ æµ‹è¯•ç¼“å­˜æ€§èƒ½")
            print("=" * 70)
            print()

        # ç¬¬ä¸€æ¬¡è¯†åˆ«ï¼ˆæ— ç¼“å­˜ï¼‰
        if self.verbose:
            print("ðŸ“Š ç¬¬ä¸€æ¬¡è¯†åˆ«ï¼ˆå†·å¯åŠ¨ï¼‰...")

        result1 = await self.test_model_inference("UI-TARS", test_image)
        time1 = result1.get("inference_time", 0)

        # å¯ç”¨ç¼“å­˜
        await self.sandbox.commands.run(
            "export CACHE_ENABLED=true"
        )

        # ç¬¬äºŒæ¬¡è¯†åˆ«ï¼ˆæœ‰ç¼“å­˜ï¼‰
        if self.verbose:
            print("ðŸ“Š ç¬¬äºŒæ¬¡è¯†åˆ«ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰...")

        result2 = await self.test_model_inference("UI-TARS", test_image)
        time2 = result2.get("inference_time", 0)

        if self.verbose and time1 > 0 and time2 > 0:
            speedup = time1 / time2
            print(f"\nðŸš€ ç¼“å­˜åŠ é€Ÿæ¯”: {speedup:.1f}x")
            print(f"   æ— ç¼“å­˜: {time1:.2f}ç§’")
            print(f"   æœ‰ç¼“å­˜: {time2:.2f}ç§’")
            print(f"   èŠ‚çœ: {(time1 - time2):.2f}ç§’\n")

        return {
            "cold_start": result1,
            "cached": result2,
            "speedup": time1 / time2 if time1 > 0 and time2 > 0 else 0
        }

    async def test_confidence_thresholds(self, test_image: str):
        """æµ‹è¯•ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„è¯†åˆ«ç»“æžœ"""
        if self.verbose:
            print("=" * 70)
            print("ðŸŽ¯ æµ‹è¯•ç½®ä¿¡åº¦é˜ˆå€¼")
            print("=" * 70)
            print()

        thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]
        results = {}

        for threshold in thresholds:
            if self.verbose:
                print(f"ðŸ“Š æµ‹è¯•é˜ˆå€¼: {threshold:.0%}")

            test_script = f'''
import asyncio
import json
from src.vision_engine import VisionEngine
from src.config import ConfigManager

async def test():
    config = ConfigManager()
    config.set("models.confidence_threshold", {threshold})
    engine = VisionEngine(config)

    result = await engine.recognize("{test_image}")

    # ç»Ÿè®¡ä¸åŒç½®ä¿¡åº¦åŒºé—´çš„å…ƒç´ 
    high = sum(1 for e in result.elements if e.confidence >= 0.8)
    medium = sum(1 for e in result.elements if 0.6 <= e.confidence < 0.8)
    low = sum(1 for e in result.elements if e.confidence < 0.6)

    output = {{
        "threshold": {threshold},
        "total_elements": len(result.elements),
        "high_confidence": high,
        "medium_confidence": medium,
        "low_confidence": low
    }}

    print(json.dumps(output, indent=2))

asyncio.run(test())
'''

            result = await self.sandbox.commands.run(
                f"cd /app && python -c '{test_script}'"
            )

            if result.exit_code == 0:
                try:
                    output = json.loads(result.stdout)
                    results[threshold] = output

                    if self.verbose:
                        print(f"   æ€»å…ƒç´ : {output['total_elements']}")
                        print(f"   é«˜ç½®ä¿¡åº¦(â‰¥80%): {output['high_confidence']}")
                        print(f"   ä¸­ç­‰(60-80%): {output['medium_confidence']}")
                        print(f"   ä½Ž(<60%): {output['low_confidence']}\n")

                except json.JSONDecodeError:
                    pass

        return results

    async def generate_report(self, results: Dict, output_file: str = "vision_test_report.json"):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report_path = Path(output_file)

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        if self.verbose:
            print(f"ðŸ“ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.sandbox:
            if self.verbose:
                print("\nðŸ§¹ æ¸…ç†æ²™ç®±...")
            await self.sandbox.close()


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="åœ¨OpenSandboxä¸­æµ‹è¯•NVDA Visionè§†è§‰è¯†åˆ«"
    )
    parser.add_argument(
        "--image",
        default="nvda-vision:latest",
        help="Dockeré•œåƒåç§°"
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=15,
        help="è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"
    )
    parser.add_argument(
        "--test-images",
        nargs="+",
        default=["tests/fixtures/screenshots/feishu_window.png"],
        help="æµ‹è¯•å›¾ç‰‡è·¯å¾„"
    )
    parser.add_argument(
        "--model",
        choices=["UI-TARS", "MiniCPM-V", "Doubao", "all"],
        default="all",
        help="è¦æµ‹è¯•çš„æ¨¡åž‹"
    )
    parser.add_argument(
        "--test-cache",
        action="store_true",
        help="æµ‹è¯•ç¼“å­˜æ€§èƒ½"
    )
    parser.add_argument(
        "--test-thresholds",
        action="store_true",
        help="æµ‹è¯•ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼"
    )
    parser.add_argument(
        "--output",
        default="vision_test_report.json",
        help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="é™é»˜æ¨¡å¼"
    )

    args = parser.parse_args()

    runner = VisionTestRunner(
        image=args.image,
        timeout_minutes=args.timeout,
        verbose=not args.quiet
    )

    try:
        # è®¾ç½®æ²™ç®±
        await runner.setup_sandbox()

        # ä¸Šä¼ æµ‹è¯•å›¾ç‰‡
        await runner.upload_test_images(args.test_images)

        # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡è¿›è¡Œæµ‹è¯•
        test_image = f"/app/tests/fixtures/screenshots/{Path(args.test_images[0]).name}"

        results = {}

        # æµ‹è¯•æ¨¡åž‹è¯†åˆ«
        if args.model == "all":
            results["models"] = await runner.test_all_models(test_image)
        else:
            results["models"] = {
                args.model: await runner.test_model_inference(args.model, test_image)
            }

        # æµ‹è¯•ç¼“å­˜æ€§èƒ½
        if args.test_cache:
            results["cache"] = await runner.test_cache_performance(test_image)

        # æµ‹è¯•ç½®ä¿¡åº¦é˜ˆå€¼
        if args.test_thresholds:
            results["thresholds"] = await runner.test_confidence_thresholds(test_image)

        # ç”ŸæˆæŠ¥å‘Š
        await runner.generate_report(results, args.output)

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æµ‹è¯•é€šè¿‡
        all_success = all(
            r.get("success", False)
            for r in results.get("models", {}).values()
        )

        sys.exit(0 if all_success else 1)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        await runner.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
