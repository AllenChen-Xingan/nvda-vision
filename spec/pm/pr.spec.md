# NVDA Vision Screen Reader - 产品需求文档 (Affordance-Driven)

**文档版本**: v1.0.0
**创建日期**: 2025-12-24
**依赖文档**: `.42cog/real/real.md`, `.42cog/cog/cog.md`
**生成技能**: pm-product-requirements (Affordance-Driven Approach)

---

## 1. 产品环境 (Product Environment)

### 1.1 基本信息

**名称**: NVDA Vision Screen Reader (NVDA视觉屏幕阅读器)

**标语**: 一个让AI的眼睛为视障人士读懂世界的行动空间

**版本**: 0.1.0 (MVP → MAS-1)

### 1.2 环境描述

NVDA Vision Screen Reader创建了一个**感知增强环境**，将原本对视障用户不可感知的视觉affordances转换为听觉affordances。通过AI视觉模型作为"视觉代理"，键盘作为"行动执行器"，用户能够感知和操作飞书、钉钉等自定义控件应用。

### 1.3 主要代理 (Primary Agents)

#### 视障用户 (Blind User Agent)
- **感知能力**: 听觉（NVDA语音）、触觉（键盘）
- **行动能力**: 键盘操作、触摸手势
- **目标**: 独立使用办公软件完成工作任务

#### AI视觉模型 (AI Vision Agent)
- **感知能力**: 屏幕像素识别、语义理解
- **行动能力**: 元素检测、坐标定位
- **目标**: 准确识别UI元素并返回结构化数据

#### NVDA核心程序 (NVDA Core Agent)
- **感知能力**: 键盘事件、焦点变化
- **行动能力**: 语音合成、事件分发
- **目标**: 提供稳定的辅助技术平台

---

## 2. Affordance故事架构 (MAS Framework)

### MAS-1: 感知不可见界面 (Perceive the Imperceptible Interface)

**故事主题**:
视障用户打开飞书，通过按下快捷键触发AI识别，听到NVDA朗读"发现3个按钮：发送消息、取消、附件"，用户导航到"发送消息"按钮并点击，成功完成操作。**原本不存在的affordance现在变得可感知、可执行。**

**核心Affordance序列**:
1. **触发识别affordance** (NVDA+Shift+V) → 启动视觉识别
2. **接收结果affordance** → 听到元素列表
3. **导航元素affordance** (NVDA+Shift+N/P) → 切换焦点
4. **激活元素affordance** (Enter) → 模拟点击

**意义闭合**: 用户从"无法感知"到"可以感知和行动"，实现能动性恢复（agency restored）

**内在动机**:
- 兴趣: 体验AI赋能的新奇感
- 掌握: 熟练使用快捷键提升效率
- 自主性: 不再依赖他人帮助

---

### MAS-2: 处理感知不确定性 (Handle Perception Uncertainty)

**故事主题**:
AI识别返回低置信度结果（60%），系统朗读"不确定：按钮：可能是提交"。用户按NVDA+Shift+R重新识别，使用备用模型后置信度提升到85%。**用户学会处理AI的不确定性。**

**核心Affordance序列**:
1. **接收不确定结果affordance** → 听到"不确定"前缀
2. **触发重新识别affordance** (NVDA+Shift+R) → 启用备用模型
3. **比较结果affordance** → 对比前后置信度
4. **授权云端调用affordance** → 明确同意后使用云端API

**意义闭合**: 培养批判性AI素养（critical AI literacy）

---

### MAS-3: 优化感知策略 (Optimize Perception Strategy)

**故事主题**:
高级用户根据使用场景调整模型优先级：工作时用GPU（准确优先），快速浏览时用CPU（速度优先）。**用户成为环境的主动塑造者。**

**核心Affordance序列**:
1. **访问配置affordance** (NVDA+Shift+C)
2. **调整模型优先级affordance** → 切换GPU/CPU优先
3. **自定义快捷键affordance** → 修改默认绑定
4. **配置缓存策略affordance** → 调整TTL时间

**意义闭合**: 从novice到expert的转变，获得掌控感

---

## 3. Affordance详细规约

### 3.1 主要Affordances (Primary)

#### AF-001: 触发屏幕识别

**启用的行动**: 启动AI视觉模型识别当前窗口UI元素

**环境属性**:
- 触发信号: NVDA+Shift+V
- 状态指示: "正在识别..."
- 持续时间: 3-15秒

**代理要求**:
- 视障用户: NVDA使用经验、键盘操作、耐心等待
- AI模型: 截图能力、UI识别能力、置信度评估

**感知-行动耦合**:
- 人类: 按键 → 听到提示 → 等待结果
- AI: 检测调用 → 截图+推理 → 返回元素列表

**约束** (来自real.md):
- ✅ 独立线程执行，不阻塞NVDA
- ✅ 超过5秒显示进度
- ✅ 超过15秒自动降级
- ✅ 异常不影响NVDA稳定性

---

#### AF-002: 导航识别到的元素

**启用的行动**: 在识别到的UI元素间移动焦点

**环境属性**:
- 导航信号: NVDA+Shift+N（下一个）/ NVDA+Shift+P（上一个）
- 状态反馈: 朗读元素类型和文本
- 循环行为: 到末尾后返回第一个

**感知-行动耦合**:
- 人类: 听到元素信息 → 判断是否目标 → 继续或激活
- 系统: 索引移动 → 生成语音文本 → TTS输出

**约束**:
- ✅ 仅导航可交互元素（button, link, textbox）
- ✅ 跳过低置信度元素

---

#### AF-003: 激活元素

**启用的行动**: 模拟鼠标点击当前焦点元素

**环境属性**:
- 激活信号: Enter键
- 执行方式: pyautogui点击元素中心坐标
- 反馈延迟: 取决于应用响应

**感知-行动耦合**:
- 人类: 按Enter → 听到应用响应
- 系统: 计算坐标 → 模拟点击 → 无反馈（点击是静默的）

**约束**:
- ✅ 低置信度元素需二次确认
- ✅ 点击前移动鼠标到目标位置

---

### 3.2 次要Affordances (Secondary)

#### AF-004: 重新识别

**启用的行动**: 使用备用模型或云端API重新识别

**触发条件**:
- 用户不满意识别结果
- 首次识别返回"不确定"
- 主动触发（NVDA+Shift+R）

**环境属性**:
- 降级策略: GPU失败 → CPU → 云端API
- 云端授权: 首次需用户明确同意

**约束**:
- ✅ 调用云端前必须告知用户
- ✅ 记录日志供审计

---

#### AF-005: 查看识别详情

**启用的行动**: 查看元素详细信息（置信度、坐标、模型）

**触发方式**: NVDA+Shift+D

**环境属性**:
- 信息内容: 类型、文本、坐标、置信度、模型名称
- 使用场景: 调试、学习、验证

---

### 3.3 潜在Affordances (Latent)

#### AF-006: 配置模型优先级

**启用的行动**: 调整GPU/CPU/云端使用顺序

**发现方式**: 阅读文档或社区询问

**环境属性**:
- 访问路径: NVDA+Shift+C → "模型设置"
- 配置选项: GPU优先/CPU优先/云端优先/禁用云端

---

#### AF-007: 自定义快捷键

**启用的行动**: 修改默认快捷键绑定

**环境属性**:
- 访问路径: NVDA+Shift+C → "快捷键设置"
- 可修改项: 识别、导航、激活、重新识别等
- 冲突检测: 自动检测与NVDA冲突

---

#### AF-008: 导出识别日志

**启用的行动**: 导出历史记录用于分析

**环境属性**:
- 访问路径: NVDA+Shift+C → "导出日志"
- 日志内容: 时间戳、应用名、结果、模型、置信度
- 隐私保护: 自动脱敏（仅保留元数据）

---

## 4. 环境约束 (Environmental Constraints)

### 4.1 物理约束

| 约束 | 对Affordances的影响 |
|------|-------------------|
| 屏幕分辨率 | 限制可识别元素数量和精度 |
| GPU显存 | 决定可用模型（≥16GB → UI-TARS） |
| 内存容量 | 限制缓存大小（最多100条） |
| 网络带宽 | 影响云端API速度（需≥1Mbps） |

### 4.2 结构约束

| 约束 | 对Affordances的影响 |
|------|-------------------|
| NVDA Plugin API | 限制可监听事件和调用功能 |
| Windows API | 决定截图和鼠标模拟方式 |
| 模型输入格式 | 限制图像预处理（最大1920px） |
| NVDA语音引擎 | 限制反馈方式（纯文本） |

### 4.3 安全约束 (来自real.md)

| 约束 | 限制 | 实现方式 |
|------|-----|---------|
| 隐私保护 | 屏幕数据优先本地处理 | 默认禁用云端，首次需授权 |
| 密钥安全 | API密钥不可明文查看 | Windows DPAPI加密 |
| 置信度透明 | 低置信度必须标注 | <70%添加"不确定"前缀 |
| 无障碍标准 | 必须键盘可访问 | 快捷键全覆盖 |
| 系统稳定性 | 插件错误不影响NVDA | 独立线程+异常处理 |
| 用户体验 | 长等待需进度提示 | >5秒提示，>15秒降级 |
| 开源合规 | 商业非商业可自由使用 | Apache 2.0许可 |

---

## 5. 感知通道 (Perception Channels)

### 5.1 听觉Affordances (主要通道)

将视觉affordances转换为听觉affordances。

| 视觉元素 | 听觉表示 | 设计模式 |
|---------|---------|---------|
| 按钮 | "按钮：{文本}" | 类型前置 |
| 输入框 | "输入框：{标签}，当前内容：{文本}" | 类型+上下文 |
| 链接 | "链接：{文本}" | 类型+文本 |
| 不确定元素 | "不确定：{类型}：{文本}，置信度{X}%" | 警告前缀 |

**设计原则**:
1. 类型优先（建立心智模型）
2. 简洁性（避免冗余）
3. 上下文相关（输入框说明当前内容）
4. 置信度透明（低置信度明确告知）
5. 可中断性（用户可按Ctrl中断）

### 5.2 触觉Affordances (辅助通道)

| 元素 | 触觉反馈 | 使用场景 |
|------|---------|---------|
| 快捷键组合 | 键盘按键肌肉记忆 | 日常高频操作 |
| 导航列表 | 连续按键节奏感 | 快速浏览 |
| 到达边界 | 无新元素朗读（停顿） | 列表末尾 |

### 5.3 跨模态Affordances

**视觉（AI）→ 听觉（用户）映射**:

| AI视觉感知 | 用户听觉感知 | Affordance桥接 |
|-----------|------------|---------------|
| bbox坐标 | "位置：屏幕中央偏右" | 空间语义化 |
| 置信度0.95 | "非常确定" | 概率语言化 |
| button类型 | "按钮" | 直接映射 |
| OCR文本 | 直接朗读 | 无转换 |

---

## 6. 反馈机制 (Feedback Mechanisms)

### 6.1 立即反馈 (<100ms)

| 行动 | 用户反馈 | 系统反馈 |
|------|---------|---------|
| 按下快捷键 | 键盘触觉 | 事件已捕获 |
| 按Enter | 键盘触觉 | 执行点击 |
| 导航元素 | 方向键触觉 | 索引移动 |

### 6.2 渐进反馈 (<5秒)

| 行动 | 用户反馈 | 系统反馈 |
|------|---------|---------|
| 触发识别 | "正在识别屏幕..." | 模型推理中 |
| 等待5秒 | "正在识别，请稍候..." | 继续推理 |
| 等待15秒 | "识别时间过长，正在切换..." | 模型降级 |

### 6.3 完成反馈 (<15秒)

| 行动 | 用户反馈 | 系统反馈 |
|------|---------|---------|
| 识别成功 | "发现3个按钮，2个输入框" | 返回元素列表 |
| 识别失败 | "识别失败，请稍后重试" | 记录错误日志 |
| 云端授权 | "是否使用云端API？Y/N" | 等待用户输入 |

---

## 7. Affordance验收标准

### 7.1 MAS-1验收标准

| ID | 标准 | 人类测试 | AI测试 | 优先级 |
|----|------|---------|--------|--------|
| MAS1-1 | 识别affordance可感知 | 用户听到快捷键提示 | 事件监听正常 | P0 |
| MAS1-2 | 识别可执行 | 3-15秒内返回结果 | 推理成功率>80% | P0 |
| MAS1-3 | 结果可理解 | 用户能理解朗读内容 | 语音文本格式正确 | P0 |
| MAS1-4 | 导航可执行 | N/P键切换元素 | 索引正确移动 | P0 |
| MAS1-5 | 激活可执行 | Enter触发点击，应用响应 | 坐标准确 | P0 |
| MAS1-6 | 不阻塞NVDA | 识别中仍可操作NVDA | 独立线程运行 | P0 |
| MAS1-7 | 缓存生效 | 相同截图<100ms返回 | 哈希匹配命中 | P1 |

### 7.2 MAS-2验收标准

| ID | 标准 | 人类测试 | AI测试 | 优先级 |
|----|------|---------|--------|--------|
| MAS2-1 | 不确定性可感知 | 听到"不确定"前缀 | 置信度<70%自动标注 | P0 |
| MAS2-2 | 重新识别可触发 | R键启动备用模型 | 模型切换正确 | P0 |
| MAS2-3 | 云端授权可控制 | 明确同意后才调用 | 首次弹出授权 | P0 |
| MAS2-4 | 结果可对比 | 能听出前后差异 | 置信度提升≥10% | P1 |

### 7.3 MAS-3验收标准

| ID | 标准 | 人类测试 | AI测试 | 优先级 |
|----|------|---------|--------|--------|
| MAS3-1 | 配置可访问 | 能打开配置界面 | 配置文件可读写 | P1 |
| MAS3-2 | 模型优先级可调整 | 能切换优先级 | 配置生效 | P1 |
| MAS3-3 | 快捷键可自定义 | 能修改快捷键 | 新快捷键正常工作 | P2 |
| MAS3-4 | 配置持久化 | 重启后配置保留 | yaml文件保存 | P1 |

---

## 8. 非Affordances (明确阻止的行动)

| 非Affordance | 为什么不支持 | 替代方案 |
|-------------|------------|---------|
| 自动识别 | 用户未请求时不主动干扰 | 用户按快捷键触发 |
| 历史记录 | 隐私风险 | 仅缓存5分钟 |
| 语音命令 | NVDA不支持语音输入 | 使用快捷键 |
| 鼠标跟随 | 视障用户无法移动鼠标 | 键盘导航 |
| 多语言UI | 首版仅中文+英文 | 后续扩展 |
| OCR导出 | 隐私风险 | 仅导出元数据 |
| 云端同步 | 单机使用 | 本地配置 |
| 实时监控 | 性能和隐私问题 | 按需触发 |

---

## 9. 技术实现映射

### 9.1 前端Affordance渲染

TTS（Text-To-Speech）作为"听觉渲染引擎"：

```python
def generate_speech(elements, config):
    parts = []
    for elem in elements:
        elem_type = elem["type"]
        elem_text = elem.get("text", "未知")

        # 置信度affordance（透明性）
        if elem["confidence"] < 0.7:
            prefix = "不确定："
        else:
            prefix = ""

        parts.append(f"{prefix}{elem_type}：{elem_text}")

    return "，".join(parts)
```

### 9.2 后端Affordance支持

| Affordance | 后端实现 | 关键类/函数 |
|------------|---------|-----------|
| AF-001 触发识别 | 异步线程+模型推理 | `RecognitionController._recognize_async()` |
| AF-002 导航元素 | 列表索引+循环 | `KeyboardNavigator.navigate_next()` |
| AF-003 激活元素 | 坐标计算+鼠标模拟 | `MouseController.click(x, y)` |
| AF-004 重新识别 | 模型降级策略 | `VisionEngine._fallback_recognition()` |

### 9.3 基础设施需求

| 基础设施 | Affordance支持 | 技术栈 |
|---------|---------------|--------|
| 模型加载器 | GPU/CPU自适应 | PyTorch, Transformers |
| 截图服务 | 快速截取窗口 | pywin32, PIL |
| 缓存系统 | 加速重复识别 | SHA-256哈希 |
| 日志系统 | 审计云端调用 | Loguru |
| 配置系统 | 持久化偏好 | PyYAML, DPAPI |

---

## 10. 附录

### 10.1 Affordance理论应用

**Gibson's Affordance Theory在NVDA Vision Reader中**:
- 飞书按钮对视障用户"不可见"（affordance不可感知）
- AI视觉模型充当"感知增强器"
- 键盘成为"行动执行器"
- 系统创造新的"感知-行动通道"

### 10.2 MAS vs MVP对比

| 维度 | MVP思维 | MAS思维 |
|------|---------|---------|
| 度量标准 | 功能完成度 | 故事完整性 |
| 优先级 | P0/P1/P2 | MAS-1/2/3 |
| 设计起点 | 功能列表 | 用户旅程 |
| 验收标准 | 功能测试 | Affordance测试 |

### 10.3 术语表

| 术语 | 定义 |
|------|-----|
| Affordance | 环境对代理提供的行动可能性 |
| MAS | Minimum Affordance Story，最小affordance故事 |
| 代理 (Agent) | 能够感知和行动的实体（人类或AI） |
| 感知通道 | 代理获取环境信息的方式 |
| 感知-行动耦合 | 感知直接引导行动 |
| 意义闭合 | 完整故事带来的心理满足感 |

---

**文档结束**

**下一步**: 生成用户故事规约（user-story.spec.md），将这些affordances展开为具体的用户旅程叙事。
